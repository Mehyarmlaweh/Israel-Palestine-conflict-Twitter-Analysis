{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abea80fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from io import StringIO\n",
    "import pickle\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from langdetect import detect, LangDetectException\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa84d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'random_forest_modelTweets.joblib'\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = joblib.load(model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e71cb441",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=\"free //. palestine // %@user ;{\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c8e2353",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetProcessor:\n",
    "    # Constructor\n",
    "    def __init__(self, tweet_data):\n",
    "        \"\"\"\n",
    "        Initializes the object with tweet data provided as a string.\n",
    "        \"\"\"\n",
    "        self.tweets = tweet_data.split('\\n')\n",
    "\n",
    "    # Method to clean tweets\n",
    "    def clean_tweet(self, tweet):\n",
    "        \"\"\"\n",
    "        Cleans up a tweet by removing unnecessary links, special characters, and spaces.\n",
    "        \"\"\"\n",
    "        # Delete links\n",
    "        tweet = re.sub(r'https\\S+', '', tweet, flags=re.MULTILINE)\n",
    "        # Delete special characters\n",
    "        tweet = re.sub(r'\\W', ' ', tweet)\n",
    "        # Replace multiple spaces with a single space\n",
    "        tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "        # Remove leading and trailing spaces\n",
    "        tweet = tweet.strip()\n",
    "        return tweet\n",
    "\n",
    "    # Method to tokenize the tweets\n",
    "    def tokenize_and_lemmatize(self, tweet):\n",
    "        \"\"\"\n",
    "        Tokenize and lemmatize a tweet by converting to lowercase, removing stop words and lemmatizing.\n",
    "        \"\"\"\n",
    "        # Division of text into units  (tokens)\n",
    "        tokens = word_tokenize(tweet)\n",
    "        # Remove punctuation and numbers, convert to lowercase\n",
    "        tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "        # Remove stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        # Lemmatization: the canonical form of a word, which represents its root or dictionary form\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "        # Join tokens into a text string\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def process_tweets(self):\n",
    "        \"\"\"\n",
    "        Applies cleanup and lemmatization functions to tweets in the string and deletes non-English words.\n",
    "        \"\"\"\n",
    "        cleaned_tweets = [self.clean_tweet(tweet) for tweet in self.tweets]\n",
    "        lang_filtered_tweets = [tweet for tweet in cleaned_tweets if self.lang(tweet)]\n",
    "        tokenized_and_lemmatized_tweets = [self.tokenize_and_lemmatize(tweet) for tweet in lang_filtered_tweets]\n",
    "\n",
    "        return tokenized_and_lemmatized_tweets\n",
    "\n",
    "    def lang(self, x):\n",
    "        \"\"\"\n",
    "        Function that detects if a tweet is in English or not.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return detect(x) == 'en'\n",
    "        except LangDetectException:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2f01d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SentimentAnalysisReport:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    def calculate_sentiment_scores(self):\n",
    "        \"\"\"\n",
    "        Calculate sentiment scores.\n",
    "        \"\"\"\n",
    "        # Check if the entry is a valid string\n",
    "        if isinstance(self.text, str):\n",
    "            compound = self.analyzer.polarity_scores(self.text)[\"compound\"]\n",
    "            pos = self.analyzer.polarity_scores(self.text)[\"pos\"]\n",
    "            neu = self.analyzer.polarity_scores(self.text)[\"neu\"]\n",
    "            neg = self.analyzer.polarity_scores(self.text)[\"neg\"]\n",
    "\n",
    "            self.sentiment_scores = {\n",
    "                \"Compound\": compound,\n",
    "                \"Positive\": pos,\n",
    "                \"Negative\": neg,\n",
    "                \"Neutral\": neu\n",
    "            }\n",
    "        else:\n",
    "            # Handle non-string values\n",
    "            self.sentiment_scores = {\n",
    "                \"Compound\": 0.0,\n",
    "                \"Positive\": 0.0,\n",
    "                \"Negative\": 0.0,\n",
    "                \"Neutral\": 1.0\n",
    "            }\n",
    "\n",
    "    def categorize_sentiment(self):\n",
    "        \"\"\"\n",
    "        Categorize sentiment based on the Compound score.\n",
    "        \"\"\"\n",
    "        compound_score = self.sentiment_scores.get(\"Compound\", 0.0)\n",
    "\n",
    "        if compound_score <= -0.5:\n",
    "            self.sentiment_category = 'Negative'\n",
    "        elif -0.5 < compound_score < 0.5:\n",
    "            self.sentiment_category = 'Neutral'\n",
    "        else:\n",
    "            self.sentiment_category = 'Positive'\n",
    "\n",
    "    def display_sentiment(self):\n",
    "        \"\"\"\n",
    "        Display the sentiment scores and category.\n",
    "        \"\"\"\n",
    "        print(\"Sentiment Scores:\")\n",
    "        for key, value in self.sentiment_scores.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "\n",
    "        print(\"Sentiment Category:\", self.sentiment_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff8e2fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_processor = TweetProcessor(test)\n",
    "cleand = tweet_processor.process_tweets()\n",
    "cleand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "867134ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your pretrained model DOC2VEC\n",
    "model = Doc2Vec.load('trained_doc2vec_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7eaac16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.1048029e-03,  2.1048170e-03,  3.8674616e-03, -2.1194341e-03,\n",
       "       -3.0556857e-03,  3.8917405e-03, -4.8500113e-03,  9.1276347e-04,\n",
       "        4.9865870e-03,  2.9245378e-03,  3.2507444e-03,  1.9515931e-04,\n",
       "        3.1592620e-03, -4.8182495e-03,  3.2734632e-04,  1.2014884e-03,\n",
       "        4.8894952e-03, -1.5125013e-03, -2.0774028e-03, -1.9986033e-03,\n",
       "       -4.9475795e-03, -1.2206477e-03, -4.9879537e-03, -1.2341264e-03,\n",
       "       -1.5432852e-03,  2.9863208e-03, -4.6120239e-03, -2.6199460e-04,\n",
       "       -2.6065835e-03,  1.0669709e-03, -1.3504979e-03, -2.6406394e-03,\n",
       "        2.0917701e-03,  4.6508447e-03,  1.1680013e-03,  1.8019611e-03,\n",
       "       -4.5624925e-03, -1.8839276e-03, -1.9951828e-03,  4.5213252e-03,\n",
       "        3.7145007e-03, -1.6019195e-03, -3.1930518e-03, -2.7568424e-03,\n",
       "       -2.7907521e-03, -4.2059505e-03,  3.2386810e-03,  6.4693985e-04,\n",
       "        6.7215861e-04, -1.1957869e-03, -2.0101955e-03, -2.7457490e-03,\n",
       "        3.7305712e-04, -4.7308714e-03,  1.3968295e-03,  4.5433831e-03,\n",
       "       -3.5442319e-03, -7.4771733e-04,  1.2723190e-03,  3.3463418e-04,\n",
       "       -2.4901936e-03,  4.7951019e-03,  3.2566786e-03,  1.6538560e-03,\n",
       "        2.4097031e-03, -1.6515076e-04,  2.3452067e-03,  1.0715240e-03,\n",
       "       -1.1762031e-03,  1.0548698e-03,  2.6268614e-03, -3.6673176e-03,\n",
       "        1.2368858e-03,  2.6486742e-03,  3.8348711e-03, -1.3802624e-03,\n",
       "        8.8752864e-04,  3.9576888e-05, -5.1447062e-04,  1.3060289e-03,\n",
       "        2.3187823e-03,  2.5331355e-03, -1.7363232e-03, -4.8301942e-03,\n",
       "        3.8991158e-03,  3.4213031e-03, -2.9622698e-03, -2.4214358e-04,\n",
       "       -4.1083037e-03,  3.3351255e-03, -8.2395109e-04,  1.8390245e-03,\n",
       "       -4.8104795e-03, -4.4041923e-03, -4.9523376e-03,  4.5749145e-03,\n",
       "        3.9517866e-03,  1.3298595e-03,  2.8011298e-03,  2.1230364e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferred_vector = model.infer_vector(cleand)\n",
    "inferred_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1bb0078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Support: [1.]\n",
      "Sentiment Scores:\n",
      "Compound: 0.0\n",
      "Positive: 0.0\n",
      "Negative: 0.0\n",
      "Neutral: 1.0\n",
      "Sentiment Category: Neutral\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted_support = loaded_model.predict([inferred_vector])\n",
    "\n",
    "\n",
    "print(\"Predicted Support:\", predicted_support)\n",
    "\n",
    "\n",
    "sentiment_report = SentimentAnalysisReport(cleand)\n",
    "\n",
    "sentiment_report.calculate_sentiment_scores()\n",
    "\n",
    "sentiment_report.categorize_sentiment()\n",
    "\n",
    "sentiment_report.display_sentiment()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
